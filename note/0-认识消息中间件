1、为什么需要使用消息队列？

消息系统主要的使用场景： 解耦、异步、削峰

下面我们就需要对这三个使用场景逐一做出说明：

- 解耦

我们先来试想这么一个场景：

A系统中会生成一条重要的数据，这条数据生成之后需要发送给BCD三个系统。如果采用调用接口的方式发送的话。
一旦需求发生变更，例如新加了EF两个系统同样需要这条数据，B系统现在又不想要这条数据了，这时可以想象一下
A系统的维护者是多麽抓狂。

然后我们引入消息队列（MQ）之后，我们来对比一下和之前使用接口传递消息有什么不同。
引入MQ之后，我们将系统改造一下。现在A系统生成这条重要数据之后，直接发送到MQ中。
接下来就和A系统没有关系了，哪个系统需要使用到这个数据的直接去MQ中消费就行了，
如果系统又不需要这条数据，直接取消对MQ的消费即可。

这样一对比就会发现，使用MQ之后。对于A系统（也就是数据提供方）来说，它根本不需要
关心数据要发送给谁，也不要关系消息是否被接收方正常接收、失败重试等情况。

***总结

你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用 MQ 给它异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个 MQ 去进行系统的解耦。


- 异步

再来设想一个场景：

A系统中有一个接口，里面需要执行非常复杂的逻辑，还需要调用另外BCD三个系统，假设这个接口本地执行逻辑耗时3ms，调用另外三个系统分别耗时200ms、300ms，400ms
这样最终请求耗时903ms，已经接近1s了，用户已经能明显的感觉出来很慢了，对于现在的互联网用户来说，这是不能忍受的


如果使用MQ，我们只需要在请求进来时记录一个初始状态，然后就将请求信息发送到MQ中，由具体的处理系统去消费处理，之后
在更新状态就可以实现异步。整个请求只需要消耗往MQ中发消息的3-5ms时间。



- 削峰

我们知道所有的业务系统都是有业务高峰期也低谷期的。比如一般的TOC系统凌晨0:00到早6:00一般都是业务的低峰期，上午9到晚9点可能是高峰期
假如A系统在低谷期TPS也就1000个左右。但是当到来到业务高峰期后TPS会暴增到1w。系统是基于Mysql，突然涌入的大量请求，会将MYSQL打死。导致
系统崩溃。

引入MQ之后，我们将所有的请求都先丢入MQ中，在高峰期每秒8000个请求，但是我们的系统每秒最多只能处理5000个请求。这时候我们只需让系统每秒钟从
MQ中拉取5000请求来处理就好了，也就是不要超过自己的处理瓶颈。这样就保证了系统在高峰期也能稳定运行，最后可能就是在高峰期 期间有大量的请求
积压在MQ中。这个短暂的请求积压是没问题的，因为一旦高峰期结束，每秒就1000个请求进来，很快就会把积压的请求给消耗掉了。


我们知道任何东西都是两面的，既然上面我们说了引入MQ能帮助我们解决很多技术上的问题，相应的引入MQ也会给我们带来一些技术难题。
也就是消息队列的有缺点

有点其实总结下来就是我们上面说的三点：
在特殊的场景下可以用来： 解耦、异步、削峰



缺点的话，有如下几个方面：

- 系统可用性降低

	系统引入的外部依赖越多，越容易down掉。
	本来系统就 A 系统调用 BCD 系统，我们引入MQ之后，这几个系统就都对MQ系统产生了依赖。
	一旦MQ 挂掉，整个系统也就无法提供服务了。

	所以这里就引入了一个问题： 我们如何保证消息系统的高可用？


- 系统复杂度提高

	引入MQ之后，我们还需要 保证消息没有被重复消费？ 如何处理消息丢失情况？ 如何保证消息传递的顺序性？

	等等问题需要我们考虑，增加整个系统的复杂度。


- 一致性问题

	在上面我们异步的例子中，我们引入MQ之后，A系统处理完就直接返回了，但是实际上，我们还需要BCD执行他们各自的逻辑
	这里如果C系统写库失败了怎么办，如何保证数据的一致性。


所以消息系统是一种非常复杂的架构，在系统引入消息队列之前一定要做好分析，看看系统是否到了非要引入消息队列的地步，如果
还没有到必须要用的地步，还是需要慎重考虑一下的，因为我们一旦引入了消息系统，我们就需要拿出一大部分精力来去处理引入消息
系统之后带来的额外问题


****
消息系统的选型


--单机吞吐量： 


ActiveMQ:   万级，比RocketMQ、Kafka低一个数量级

RabbitMQ:   同 ActiveMQ

RocketMQ:   10万级，支撑高吞吐量

Kafka:      10万级，高吞吐，一般配合大数据类系统来进行实时数据计算、日志采集等场景



-- topic数量对吞吐量的影响



ActiveMQ:   无 topic

RabbitMQ:   无 topic

RocketMQ： topic可以达到几百/几千的级别，吞吐量会有小幅度的下降，这是RocketMQ的一大优势，在同等机器下，可以支撑大量的topic

Kafka：  topic从几十到几百时，吞吐量会大幅度下降，在同等机器下，Kafka尽量保证topic数量不要过多。如果需要支撑打过莫topic，需要增加更多机器资源


--  时效性

ActiveMQ: 	ms级

RabbitMQ:  微妙级，这是RabbitMQ的一大特点，延迟最低

RocketMQ:   ms级

Kafka:     延迟在ms级以内


-- 可用性

ActiveMQ： 高，基于主从架构实现高可用

RabbitMQ： 同ActiveMQ

RocketMQ： 非常高，分布式架构

KafKa： 非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用


-- 消息可靠性

ActiveMQ： 有较低概率丢失数据

RabbitMQ:  基本不丢

RocketMQ： 经过优化可以做到0丢失

Kafka：  同RocketMQ


-- 功能支持

ActiveMQ: MQ领域功能极其完备

RabbitMQ: 基于erlang开发，并发能力很强，性能你极好，延迟很低

RocketMQ: MQ功能较为完善，分布式拓展好

Kafka： 功能较为简单，主要支持简单的MQ功能，在大数据领域的实时计算以及日志采集被大规模使用





通过上面对几种消息队列的特点做出的比较，这实际项目选型的时候，我们需要仔细斟酌一下，结合我们系统
的特点来选取合适的消息中间件


***下面有一些选型方面的建议，大家可以参考一下。

ActiveMQ  不建议选用： 没经过大规模吞吐量场景验证，社区不活跃

RabbitMQ       推荐：  开源，社区比较活跃有稳定支持。 （erlang语言实现，对Java工程师来说有一定深入难度）


RocketMQ       推荐： 开源，阿里出品，目前已移交Apache

Kafka: 		   如果是大数据领域的实时计算、日志采集等场景。用KafKa是业内的标准了。没有什么需要考虑的。






2、如何保证消息队列的高可用？


这个问题这么问是很好的，因为不能问你 Kafka 的高可用性怎么保证？ActiveMQ 的高可用性怎么保证？一个面试官要是这么问就显得很没水平，人家可能用的就是 RabbitMQ，没用过 Kafka，你上来问人家 Kafka 干什么？这不是摆明了刁难人么。

所以有水平的面试官，问的是 MQ 的高可用性怎么保证？这样就是你用过哪个 MQ，你就说说你对那个 MQ 的高可用性的理解。


-- RabbitMQ 的高可用：

RabbitMQ 是基于主从（非分布式）做的高可用。 所以用RabbitMQ 来代表基于主从模式实现高可用。

RabbitMQ 有三种模式： 单机模式、普通集群模式、镜像集群模式


- 单机模式： 单机模式，Dome级别的。 一般就是自己本地启动玩玩，用作本地的开发环境。


- 普通集群模式（无高可用性）： 

	在多台机器上面启动多个RabbitMQ实例，虽然在没台机器上面都有一个RabbitMQ 实例，但是创建的queue，只会放在一个RabbitMQ 实例上。
	但是每个queue都会同步元数据（元数据可是queue的一些配置信息，通过元数据，可以找到queue所在的实例）。你消费的时候，实际上如果连接
	到另外一个实例上面，那这个实例会从queue所在实例拉取数据过来


- 镜像集群模式

	这种模式，才能提供RabbitMQ的高可用，跟不同集群模式不同的是，在镜像集群模式下，你创建的queue，无论是元数据还是queue上面的消息都会存在多个实例上面
	即，每个RabbitMQ节点都有这个queue的一个完整的镜像，包含queue的全部数据，然后写消息到queue上面的时候，都会自动消息同步到多个实例的queue上面



*** 如何开启这个镜像集群模式/

RabbitMQ 有很好的控制管理台，要开启这个镜像集群模式，其实只需要在后台增加一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点,
也可以指定同步到节点的数量，再次创建queue的时候,应用这个策略，就会自动将数据同步到其他实例上面。




-- Kafka 的高可用

	KafKa 架构： 由多个broker组成；当我们创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同broker上，每个partition就放一部分数据。

	Kafka从架构的设计上就是分布式的， 一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。




3、如何保证消息不被重复消费？（保证消息的幂等）

	首先，rabbitMQ、RocketMQ、Kafka 都有可能会出现消息的重复消费问题，这是正常的。因为这问题通常不是MQ来保证的，是有我么的业务代码来控制的。

	重复消费的情况：

	拿Kafka来举例---kafka有个offset的概念（偏移量），就是每个消息写到消息队列之后，都会有一个offset，代表消息的序号。之后如果消费者消费了
	该条数据之后，每隔一段时间（定时定期），会把消费过的消息的offset提交一下，下次如果重启后，会继续上次消费到的offset来接着消费。

	在实际生产中，我们可能会出现各种原因导致kafka的offset提交不成功。比如网络波动、或者异常断电等不可控制的原因导致offset提交失败，这样
	消费者就会重复消费之前其实已经消费过但是offset提交失败的这部分数据。


	重复消费会对我们造成什么影响呢？
	这样说，比如我们有个需求是从MQ中消费数据，然后将数据写到我们的数据库中，这里如果出现重复消费的话，如果我们没做特殊约束，相同的数据就会
	多次入库，也就造成了我们库中的数据错误。

	保证幂等-简单来说就是同一数据操作多次，对我们的数据正确性是没有影响的。

	下面提供开发中解决重复消费的实现方案--可以根据自身业务选择合适的方案：

	- 如果是从MQ中拿数据写库，可以先根据数据中的唯一键先到去数据库中查一下，如果存在就代表这次是重复消费，直接丢弃就行了

	- 如果是写redis，set操作会覆盖，天然幂等

	- 如果不是上面两个场景，那在消息生产和消费的时候会麻烦一些。我们在生产消息的时候，可以在每条数据中添加一个唯一ID。
	  然后消费者消费到之后，先用这个id去redis中查一下，如果有就代表重复消费，丢弃。如果没有正常处理，并将ID放到redis

	  上面的redis也可换成局域数据可主键






4、如何保证消息的可靠传输？

	上面说的解决重复消费的问题，是解决数据多了的问题，下面保证消息的可靠传输是解决数据少了的问题。无论是数据是多了还是少了
	我们都是不能接受的。

	数据的丢失问题，可能发生在 生产者、MQ、消费者中，这里我们可以来一起看下rabbitMQ 和 Kafka 中可能出现消息丢失的情况。


	-- RabbitMQ：




	生产者 --------->  RabbitMQ  -------------> 消费者

	1： 消息在传入MQ过程中丢失
	2： RabbitMQ收到消息，暂存内存中，还没消费，MQ异常关闭，内存中数据丢失
	3： 消费者消费到了这个消息，但还没来得及处理，就异常关闭，RabbitMQ以为消息已经被处理了


	** 生产者丢失数据 **

	生产者将数据发送到RabbitMQ的过程中，数据可能丢失，可能因为网络或者异常宕机等等原因

	解决RabbitMQ 生产者丢失消息可以选择RabbitMQ提供的事务功能。
	-- 在生产者发送数据之前开启RabbitMQ事务 channel.txSelect
	-- 发送消息后，如果消息没有被RabbitMQ成功接收的话，生产者会受到异常，此时捕获异常，进行事务回滚 channel.txRollback，然后重试
	-- 最后提交事务 channel.txCommit


	** 伪代码


		// 开启事务
		channel.txSelect
		try {
		    // 这里发送消息
		} catch (Exception e) {
		    channel.txRollback

		    // 这里再次重发这条消息
		}

		// 提交事务
		channel.txCommit


     但是我们使用，RabbitMQ事务机制（同步），对系统的吞吐量影响很大，很耗性能



     其实RabiitMQ解决生产消息丢失还有一种方式，也是我们一般采用的方式。
     就是开启 RabbitMQ的confirm模式。我们这里在生产者设置开启confirm模式，之后我们每次写入消息都会分配一个唯一ID,
     然后如果写入RabbitMQ中成功之后，RabbitMQ会回传一个ack消息，告诉你这个消息写入成功。
     如果RabbitMQ写入失败，会回调我们一个nack 接口，通知我们这个消息写入失败，我们就可以根据这个对消息进行重试 。
     我们可以维护一下我们的这个消息ID,如果在一定时间内我们没有收到消息的结果回调，我们就认为消息写入失败了，进行消息重发。

     这里的confirm 机制和事务机制最大区别在于，事务机制是一个同步的过程，整个过程是一个阻塞的状态，而comfirm机制是异步的，
     我们发送消息之后可以立即发送下一个消息，消息的发送结果RabbitMQ会通过回调接口的方式异步通知到生产者。


     ** RabbitMQ 丢失数据 **

     要解决RabbitMQ丢失消息，必须开启RabbitMQ 的持久化配置，就是消息写入之后需要落盘。这样即使RabbitMQ异常宕机，恢复之后也能
     自动读取之前存储的数据。 

     有一点需要注意的是，就算开启RabbitMQ的持久化，也还是有极小的概率会丢失少量消息。这种情况就是，在RabbitMQ还没来的急将数据
     持久化，自己就宕机。可能导致这部分还未持久化的数据丢失。但是这个概率很小。

     设置持久化的步骤：

     - 创建queue的时候设置其为持久化 （这样可以保证RabbitMQ持久化queue的元数据，但是不会持久化queue中的数据）

     - 第二在发送消息的时候将消息的 deliverMode设置为2（将数据持久化）

     以上两个都必须同时设置才行

     我们设置了数据持久化之后，数据还是会有极小的概率丢失，这是我们可以将数据持久化和我们生产者 confirm机制配合起来，
     只有当消息持久化磁盘之后，我们才会返回ack消息。 之后如果消息是在持久化之前意外宕机导致的数据丢失，生产者接受不到
     ack消息，我们可以对消息进行重发。


     ** 消费端 丢失数据 **

     消费端丢失消息，就是我们消费到了消息，但是还没来得急处理这条消息，消费者就异常宕机了，这时候RabbitMQ认为该条消息已经被消费。

     这个时候我们得使用RabbitMQ的ack机制。首先我们得关闭RabbitMQ的自动ack。 通过自己在处理代码中手动ack，在消息处理成功之后，我们提交
     ack信息。




	DJ PRO FOR AI FAST


	-- kafka：



	** 消费端丢失消息 **


	我们前面已经了解过了，kafka里面有个offset的概念。通过offset来判断消息消费的位置。
	Kafka消费端丢失消息的唯一可能就是，消费者已经消费到了消息，同时也自动提交了offset。
	但是这是消费者刚开始要处理这条消息的时候，异常宕机了。这就导致kafka已经认为该条消息
	已经被消费。但是实际上消息没有被正常处理。


	其实这里，如果同学们仔细想一下就会发现。这里我们处理kafka消费端丢失消息其实和我们rabbitMQ
	处理本质上是一样的。只需要将自动offset提交，变成在我们正确处理完消息后手动提交消息就好了。
	当然这样有可能会造成消息的重复消费，也就是我们消息处理完了，在正准备提交offset的时候，消费者
	宕机。导致offset未提交。其实这里我们只需要使用我之前的方案控制下幂等就行了。这和我们解决RabbitMQ
	其实一样，只不过RabbitMQ是ack机制。这里是offset机制。


	** Kafka 丢数据 **


	Kafka 丢数据一般发生在， 当某个broker宕机后，重新选举partition的leader 的场景。
	此时要是其他的follower刚好有数据还未同步。结果此时leader宕机。然后选举某个follower
	成为leader之后，就丢失一部分数据。

	这种情况我们可以通过对集群配置做一些调整来解决


	-*- 给topic设置 replication.factor 参数： 这个值必须大于1，（要求每个partition必须至少有2个副本）

	-*- 在kafka服务端设置 min.insync.replicas 参数： 这个值必须大于1（要求一个leader至少感知到至少有一个follower的心跳。确保leader宕机还至少有一个follower）

	-*- 在producer端设置 acks=all: 这是要求每条数据必须写入所有replication之后，才返回成功

	-*- 在producer端设置 retries=MAX: 一旦写入失败，无限次重试



	** 生产者丢失数据 **

	如果上面配置设置 acks=all  数据是不会再生产者端丢失的。


5、如何保证消息的顺序性？


	当我们消费数据的逻辑需要保证和消息进入MQ的顺序一致时，我们如何保证消费消息的顺序性。


	如果我们有个业务是需要同步mysql的 binlog 日志进行备份。
	当我们对mysql中的一条数据进行 增删改  操作之后。对应出增删改3条binlog日志。接着这这三条
	binlog按照顺序发送到MQ中。当我们消费出来执行时，这是一定要保证我们的顺序。不然我们的数据
	就会错乱。


	- 乱序场景

	RabbitMQ：

	一个queue，多个consumer。


	生产者向RabbitMQ中发了三条数据，顺序依次是 data1/data2/data3.
	压入的是RabbitMQ的一个内存队列。如果这时有三个消费者从MQ消费消息
	我们是没办法保证这三条数据的消费顺序的。



	KafKa：

	比如创建了一个topic，有三个partition。

	生产者在写数据的时候，可以为每条数据指定一个key，比如说我们指定了某个订单 id 作为 key，
	那么这个订单相关的数据，一定会被分发到同一个 partition 中去，而且这个 partition 中的数据一定是有顺序的。

	消费者从partition中取数据的时候也是有顺序的。这里我们的顺序都没问题。但是如果我们再消息者里面搞多线程来并发
	处理消息的话，顺序就有可能乱掉了。

	-- 解决方案：

	RabbitMQ:

	拆分多个queue，每个queue一个consumer。

	Kafka：

	- 一个topic，一个partition，一个consumer，内部单线程消费。 （吞吐量太低，消息可靠性降低，不建议采用）

	- 写N个内存queue，具有相同key的数据都到同一个内存queue。然后对于N个线程，每个线程分一个内存queue，这样就能保证消息的消费顺序。




6、如果消息在消息队列中大量积压了怎么办？



如果线上消费端故障导致消息大量积压在消息队列中，如何快速处理掉积压掉的消息。

这个时候就要紧急扩容了。

- 先修复消费端的问题，确保其能正常消费之后，然后将现有的消费端都停掉

- 新建一个临时的topic，partition是原来的10倍，临时建立好原来10倍数量的queue

- 然后写一个临时分发数据的消费程序，这个程序里面不需要做其他额外的处理，只需要将消息轮询写入先建好的10倍数量的queue中

- 接着部署10倍的消息正常处理的消费者，分别去消费10倍数量queue中的数据，以10倍速度消费掉积压的数据

-等消息积压消费差不多之后 可以先停掉临时分发数据的消费端，之后恢复正常的消费架构



--- 设计一个消息系统思路


首先这个 mq 得支持可伸缩性吧，就是需要的时候快速扩容，就可以增加吞吐量和容量，那怎么搞？设计个分布式的系统呗，参照一下 kafka 的设计理念，broker -> topic -> partition，每个 partition 放一个机器，就存一部分数据。如果现在资源不够了，简单啊，给 topic 增加 partition，然后做数据迁移，增加机器，不就可以存放更多数据，提供更高的吞吐量了？

其次你得考虑一下这个 mq 的数据要不要落地磁盘吧？那肯定要了，落磁盘才能保证别进程挂了数据就丢了。那落磁盘的时候怎么落啊？顺序写，这样就没有磁盘随机读写的寻址开销，磁盘顺序读写的性能是很高的，这就是 kafka 的思路。

其次你考虑一下你的 mq 的可用性啊？这个事儿，具体参考之前可用性那个环节讲解的 kafka 的高可用保障机制。多副本 -> leader & follower -> broker 挂了重新选举 leader 即可对外服务。

能不能支持数据 0 丢失啊？可以的，参考我们之前说的那个 kafka 数据零丢失方案。



1、为什么需要使用消息队列？

2、消息队列如何选型？

3、如何保证消息队列的高可用？

4、如何保证消息不被重复消费？（保证消息的幂等）

5、如何保证消息的可靠传输？

6、如何保证消息的顺序性？

7、如果消息在消息队列中大量积压了怎么办？

最后会有实战课程  通用消息发送系统开发